{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import os,glob\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to /Users/chengchengchen/extracted_files\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "# Path to the zip file\n",
    "zip_path = r'/Users/chengchengchen/Desktop/桌面清理大师/VSC/Sentiment_Labelled_Sentences.zip'  # Update with the correct path to combined.zip\n",
    "\n",
    "# Extract the zip file\n",
    "#with ZipFile(zip_path, 'r') as zip_ref:\n",
    "#    zip_ref.extractall('/content')  # Extract to /content or any preferred directory\n",
    "\n",
    "# Extract the zip file to a writable directory\n",
    "extract_path = os.path.expanduser('~/extracted_files')  # Extract to ~/extracted_files\n",
    "os.makedirs(extract_path, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "with ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)  # Extract to the specified writable directory\n",
    "\n",
    "print(f\"Files extracted to {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'amazon_cells_labelled.txt', 'readme.txt', 'yelp_labelled.txt', 'imdb_labelled.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the extracted folder\n",
    "extracted_folder = os.path.expanduser('~/extracted_files/sentiment labelled sentences')\n",
    "\n",
    "# Check and list contents\n",
    "if os.path.exists(extracted_folder):\n",
    "    print(os.listdir(extracted_folder))\n",
    "else:\n",
    "    print(f\"The folder {extracted_folder} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  score source\n",
      "0  A very, very, very slow-moving, aimless movie ...      0   imdb\n",
      "1  Not sure who was more lost - the flat characte...      0   imdb\n",
      "2  Attempting artiness with black & white and cle...      0   imdb\n",
      "3       Very little music or anything to speak of.        0   imdb\n",
      "4  The best scene in the movie was when Gerardo i...      1   imdb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the folder\n",
    "folder_path = os.path.expanduser('~/extracted_files/sentiment labelled sentences')\n",
    "\n",
    "# Files to load\n",
    "files = ['imdb_labelled.txt', 'amazon_cells_labelled.txt', 'yelp_labelled.txt']\n",
    "\n",
    "# Load all files into a single DataFrame\n",
    "dataframes = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['sentence', 'score'])\n",
    "    df['source'] = file.split('_')[0]  # Add a source column based on file name\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "1    1386\n",
      "0    1362\n",
      "Name: count, dtype: int64\n",
      "source  score\n",
      "amazon  0        500\n",
      "        1        500\n",
      "imdb    1        386\n",
      "        0        362\n",
      "yelp    0        500\n",
      "        1        500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['score'].value_counts())\n",
    "print(data.groupby('source')['score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "0    1300\n",
      "1     200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `data` is your DataFrame\n",
    "\n",
    "# Filter the data for each score\n",
    "negative_samples = data[data['score'] == 0].sample(n=1300, random_state=42)\n",
    "positive_samples = data[data['score'] == 1].sample(n=200, random_state=42)\n",
    "\n",
    "# Combine the samples\n",
    "balanced_data = pd.concat([negative_samples, positive_samples])\n",
    "\n",
    "# Shuffle the resulting dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the new distribution\n",
    "print(balanced_data['score'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Combine all files into one DataFrame\n",
    "for file in files:\n",
    "    file_path = os.path.expanduser(f'{folder_path}/{file}')\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['sentence', 'score'])\n",
    "    dataframes.append(df)\n",
    "\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Preprocess the text\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=200)  # Limit features to 5000\n",
    "X = tfidf.fit_transform(balanced_data['sentence'])\n",
    "y = balanced_data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Soft-margin SVM using CVXPY\n",
    "def soft_margin_svm(X, y, C):\n",
    "    \"\"\"\n",
    "    Solves the soft-margin SVM problem using CVXPY\n",
    "    Args:\n",
    "    - X: Data matrix of shape (m, n) where m is the number of points and n is the dimension (features).\n",
    "    - y: Labels vector of shape (m,) with entries in {-1, 1}.\n",
    "    - C: Regularization parameter.\n",
    "    Returns:\n",
    "    - b: Coefficient vector of shape (n,)\n",
    "    - c: Intercept (scalar)\n",
    "    - xi: Slack variables vector of shape (m,)\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Define the variables\n",
    "    b = cp.Variable(n)    # weight vector\n",
    "    c = cp.Variable()     # bias\n",
    "    xi = cp.Variable(m)   # slack variables\n",
    "\n",
    "    # Define the objective function: minimize (1/2) * ||b||^2 + C * sum(xi)\n",
    "    objective = cp.Minimize(0.5 * cp.sum_squares(b) + C * cp.sum(xi))\n",
    "\n",
    "    # Define the constraints: y_i * (b^T x_i + c) >= 1 - xi_i, xi_i >= 0\n",
    "    constraints = [y[i] * (X[i] @ b + c) >= 1 - xi[i] for i in range(m)]\n",
    "    constraints += [xi >= 0]\n",
    "\n",
    "    # Solve the problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    # Return the solution: b, c, and xi\n",
    "    return b.value, c.value, xi.value\n",
    "\n",
    "# Function to predict using the learned SVM model\n",
    "def predict(X, b, c):\n",
    "    return np.sign(X @ b + c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert labels in y_train to 1 and -1\n",
    "# 1 is postive, -1 is negative\n",
    "y_train = np.where(y_train == 0, -1, y_train)  # Replace 0 with -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 88.42%\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      1.00      0.94      1033\n",
      "           1       0.89      0.19      0.32       167\n",
      "\n",
      "    accuracy                           0.88      1200\n",
      "   macro avg       0.89      0.59      0.63      1200\n",
      "weighted avg       0.88      0.88      0.85      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Run the SVM (Soft-margin SVM)\n",
    "C = 1.0  # Regularization parameter\n",
    "b_opt, c_opt, xi_opt = soft_margin_svm(X_train, y_train, C)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred_train = predict(X_train, b_opt, c_opt)\n",
    "\n",
    "y_pred_test = predict(X_test, b_opt, c_opt)\n",
    "\n",
    "# Compute accuracy and display classification report\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def USVM(A, B, n_universum, C=1.0, C_u=1.0, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Universum SVM for any binary classification task.\n",
    "\n",
    "    Args:\n",
    "    - A: Matrix of points for class 1 (positive class).\n",
    "    - B: Matrix of points for class -1 (negative class).\n",
    "    - n_universum: Number of universum points to generate.\n",
    "    - C: Regularization parameter for training data.\n",
    "    - C_u: Regularization parameter for universum data.\n",
    "    - epsilon: Margin for universum points.\n",
    "\n",
    "    Returns:\n",
    "    - b_opt: Optimal weight vector.\n",
    "    - c_opt: Optimal bias term.\n",
    "    - universum_points: Generated universum points.\n",
    "    \"\"\"\n",
    "\n",
    "    n_class1, n_features = A.shape\n",
    "    n_class_minus_1 = B.shape[0]\n",
    "\n",
    "    # Generate Universum points by averaging randomly selected points from both classes\n",
    "    random_indices_class_1 = np.random.choice(n_class1, n_universum, replace=True)\n",
    "    random_indices_class_minus_1 = np.random.choice(n_class_minus_1, n_universum, replace=True)\n",
    "    universum_points = (A[random_indices_class_1] + B[random_indices_class_minus_1]) / 2\n",
    "\n",
    "    # Combine the classes into a single dataset\n",
    "    X_train = np.vstack((A, B))\n",
    "    y_train = np.hstack((np.ones(n_class1), -np.ones(n_class_minus_1)))\n",
    "\n",
    "    # Variables for optimization\n",
    "    b = cp.Variable(n_features)  # We use 'b' for the weight vector\n",
    "    c = cp.Variable()\n",
    "    xi = cp.Variable(n_class1 + n_class_minus_1)  # Slack variables for misclassification\n",
    "    psi = cp.Variable(n_universum)  # Slack variables for universum points (positive side)\n",
    "    phi = cp.Variable(n_universum)  # Slack variables for universum points (negative side)\n",
    "\n",
    "    # Constraints\n",
    "    constraints = []\n",
    "\n",
    "    # For class 1 (label +1)\n",
    "    for i in range(n_class1):\n",
    "        constraints.append(A[i, :] @ b + c >= 1 - xi[i])\n",
    "\n",
    "    # For class -1 (label -1)\n",
    "    for i in range(n_class_minus_1):\n",
    "        constraints.append(B[i, :] @ b + c <= -1 + xi[n_class1 + i])\n",
    "\n",
    "    # Universum constraints\n",
    "    for j in range(n_universum):\n",
    "        constraints.append(universum_points[j, :] @ b + c <= epsilon + psi[j])\n",
    "        constraints.append(universum_points[j, :] @ b + c >= -epsilon - phi[j])\n",
    "\n",
    "    # Non-negative slack variables\n",
    "    constraints += [xi >= 0, psi >= 0, phi >= 0]\n",
    "\n",
    "    # Objective function: minimize the sum of errors and regularization term\n",
    "    objective = cp.Minimize(0.5 * cp.norm(b, 2)**2 + C * cp.sum(xi) + C_u * (cp.sum(psi) + cp.sum(phi)))\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "    # Get the optimal values of b and c\n",
    "    b_opt = b.value\n",
    "    c_opt = c.value\n",
    "\n",
    "    return b_opt, c_opt, universum_points\n",
    "\n",
    "def predict(X, b, c):\n",
    "    \"\"\"\n",
    "    Predict the labels based on the decision boundary.\n",
    "\n",
    "    Args:\n",
    "    - X: Data points.\n",
    "    - b: Optimal weight vector.\n",
    "    - c: Optimal bias term.\n",
    "\n",
    "    Returns:\n",
    "    - Predictions (1 or -1).\n",
    "    \"\"\"\n",
    "    return np.sign(X @ b + c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.17%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.91      0.92      1033\n",
      "           1       0.50      0.57      0.54       167\n",
      "\n",
      "    accuracy                           0.86      1200\n",
      "   macro avg       0.72      0.74      0.73      1200\n",
      "weighted avg       0.87      0.86      0.87      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "A = X_train[y_train == 1]  \n",
    "B = X_train[y_train == -1]\n",
    "n_universum = 1100\n",
    "\n",
    "# Run the Universum SVM\n",
    "b_opt, c_opt, universum_points = USVM(A, B, n_universum, C =1, C_u =1, epsilon=0.1)\n",
    "\n",
    "\n",
    "# Predict the labels based on the learned decision boundary\n",
    "y_pred = predict(X_train, b_opt, c_opt)\n",
    "\n",
    "# Compute the accuracy score\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsvm(A, B, C1=1.0, C2=1.0):\n",
    "    \"\"\"\n",
    "    TSVM\n",
    "\n",
    "    Args:\n",
    "    - A: Matrix of points for class 1 (positive class).\n",
    "    - B: Matrix of points for class -1 (negative class).\n",
    "    - n_universum: Number of Universum points to generate.\n",
    "    - C1: Regularization parameter for class 1.\n",
    "    - C2: Regularization parameter for class -1.\n",
    "\n",
    "    Returns:\n",
    "    - b1_opt, c1_opt: Optimal weight vector and bias for class 1 hyperplane.\n",
    "    - b2_opt, c2_opt: Optimal weight vector and bias for class -1 hyperplane.\n",
    "    \"\"\"\n",
    "\n",
    "    n_class1, n_features = A.shape\n",
    "    n_class_minus_1 = B.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Optimization variables for Class 1\n",
    "    b1 = cp.Variable(n_features)\n",
    "    c1 = cp.Variable()\n",
    "    xi1 = cp.Variable(n_class_minus_1)  # Slack variables for class -1 constraints\n",
    "    \n",
    "    # Optimization variables for Class 2\n",
    "    b2 = cp.Variable(n_features)\n",
    "    c2 = cp.Variable()\n",
    "    xi2 = cp.Variable(n_class1)  # Slack variables for class 1 constraints\n",
    "  \n",
    "\n",
    "    # Objective function for Class 1\n",
    "    objective1 = cp.Minimize(0.5 * cp.norm(A @ b1 + c1, 2)**2 + C1 * cp.sum(xi1))\n",
    "\n",
    "    # Constraints for Class 1\n",
    "    constraints1 = [\n",
    "        -B @ b1 - c1 + xi1 >= np.ones(n_class_minus_1),\n",
    "        xi1 >= 0  # Class -1 points\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 1\n",
    "    problem1 = cp.Problem(objective1, constraints1)\n",
    "    problem1.solve()\n",
    "    b1_opt = b1.value\n",
    "    c1_opt = c1.value\n",
    "\n",
    "    # Objective function for Class 2\n",
    "    objective2 = cp.Minimize(0.5 * cp.norm(B @ b2 + c2, 2)**2 + C2 * cp.sum(xi2))\n",
    "\n",
    "    # Constraints for Class 2\n",
    "    constraints2 = [\n",
    "        A @ b2 + c2 + xi2 >= np.ones(n_class1),\n",
    "        xi2 >= 0   # Class 1 points\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 2\n",
    "    problem2 = cp.Problem(objective2, constraints2)\n",
    "    problem2.solve()\n",
    "    b2_opt = b2.value\n",
    "    c2_opt = c2.value\n",
    "\n",
    "    return b1_opt, c1_opt, b2_opt, c2_opt\n",
    "\n",
    "def predict(X, b1_opt, c1_opt, b2_opt, c2_opt):\n",
    "    \"\"\"\n",
    "    Predicts the labels for the given data points using TSVM with learned hyperplanes.\n",
    "\n",
    "    Args:\n",
    "    - X: Input data points, shape (n_samples, n_features).\n",
    "    - b1_opt: Optimal weight vector for class 1 hyperplane.\n",
    "    - c1_opt: Optimal bias for class 1 hyperplane.\n",
    "    - b2_opt: Optimal weight vector for class -1 hyperplane.\n",
    "    - c2_opt: Optimal bias for class -1 hyperplane.\n",
    "\n",
    "    Returns:\n",
    "    - y_pred: Predicted labels for the data points, +1 or -1.\n",
    "    \"\"\"\n",
    "    # Calculate distance from hyperplane 1 (class +1)\n",
    "    distance_to_class1 = np.abs(np.dot(X, b1_opt) + c1_opt)\n",
    "    \n",
    "    # Calculate distance from hyperplane 2 (class -1)\n",
    "    distance_to_class2 = np.abs(np.dot(X, b2_opt) + c2_opt)\n",
    "    \n",
    "    # Assign label based on which hyperplane is closer\n",
    "    y_pred = np.where(distance_to_class1 < distance_to_class2, 1, -1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(42)\n",
    "\n",
    "A = X_train[y_train == 1]  \n",
    "B = X_train[y_train == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.99      0.94      1033\n",
      "           1       0.87      0.33      0.48       167\n",
      "\n",
      "    accuracy                           0.90      1200\n",
      "   macro avg       0.89      0.66      0.71      1200\n",
      "weighted avg       0.90      0.90      0.88      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train tSVM\n",
    "b1_opt, c1_opt, b2_opt, c2_opt  = tsvm(\n",
    "    A, B, C1=1.0, C2=1.0)\n",
    "\n",
    "X_train_dense = X_train.toarray()  # Convert to dense format\n",
    "\n",
    "# Predict on the train data\n",
    "y_pred = predict(X_train_dense, b1_opt, c1_opt, b2_opt, c2_opt)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import issparse\n",
    "def UTSVM(X, y, n_universum=25, C1=1.0, C2=1.0, Cu=1.0, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Universum Twin SVM.\n",
    "\n",
    "    Args:\n",
    "    - X: Training matrix\n",
    "    - y: Labels vector\n",
    "    - n_universum: Number of Universum points to generate.\n",
    "    - C1: Regularization parameter for class 1.\n",
    "    - C2: Regularization parameter for class -1.\n",
    "    - Cu: Regularization parameter for Universum points.\n",
    "    - epsilon: Margin for Universum points.\n",
    "\n",
    "    Returns:\n",
    "    - b1_opt, c1_opt: Optimal weight vector and bias for class 1 hyperplane.\n",
    "    - b2_opt, c2_opt: Optimal weight vector and bias for class -1 hyperplane.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # A: Matrix of points for class 1 (positive class)\n",
    "    #A = X[y==1]\n",
    "    # B: Matrix of points for class -1 (negative class)\n",
    "    #B = X[y==-1]\n",
    "\n",
    "    n_class1, n_features = A.shape\n",
    "    n_class_minus_1 = B.shape[0]\n",
    "\n",
    "\n",
    "    # Generate Universum points by averaging randomly selected points from both classes\n",
    "    random_indices_class_1 = np.random.choice(n_class1, n_universum, replace=True)\n",
    "    random_indices_class_minus_1 = np.random.choice(n_class_minus_1, n_universum, replace=True)\n",
    "    U = (A[random_indices_class_1] + B[random_indices_class_minus_1]) / 2\n",
    "\n",
    "    # Optimization variables for Class 1\n",
    "    b1 = cp.Variable(n_features)\n",
    "    c1 = cp.Variable()\n",
    "    xi1 = cp.Variable(n_class_minus_1)  # Slack variables for class -1 constraints\n",
    "    psi1 = cp.Variable(n_universum)  # Slack variables for Universum points (class 1)\n",
    "\n",
    "    # Optimization variables for Class 2\n",
    "    b2 = cp.Variable(n_features)\n",
    "    c2 = cp.Variable()\n",
    "    xi2 = cp.Variable(n_class1)  # Slack variables for class 1 constraints\n",
    "    psi2 = cp.Variable(n_universum)  # Slack variables for Universum points (class -1)\n",
    "\n",
    "    # Objective function for Class 1\n",
    "    objective1 = cp.Minimize(0.5 * cp.norm(A @ b1 + c1, 2)**2 + C1 * cp.sum(xi1) + Cu * cp.sum(psi1))\n",
    "\n",
    "    # Constraints for Class 1\n",
    "    constraints1 = [\n",
    "        -B @ b1 - c1 + xi1 >= np.ones(n_class_minus_1),  # Class -1 points\n",
    "        U @ b1 + c1 + psi1 >= (-1 + epsilon) * np.ones(n_universum),  # Universum points\n",
    "        xi1 >= 0, psi1 >= 0  # Non-negative slack variables\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 1\n",
    "    problem1 = cp.Problem(objective1, constraints1)\n",
    "    problem1.solve()\n",
    "    b1_opt = b1.value\n",
    "    c1_opt = c1.value\n",
    "\n",
    "    # Objective function for Class 2\n",
    "    objective2 = cp.Minimize(0.5 * cp.norm(B @ b2 + c2, 2)**2 + C2 * cp.sum(xi2) + Cu * cp.sum(psi2))\n",
    "\n",
    "    # Constraints for Class 2\n",
    "    constraints2 = [\n",
    "        A @ b2 + c2 + xi2 >= np.ones(n_class1),  # Class 1 points\n",
    "        -U @ b2 - c2 + psi2 >= (-1 + epsilon) * np.ones(n_universum),  # Universum points\n",
    "        xi2 >= 0, psi2 >= 0  # Non-negative slack variables\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 2\n",
    "    problem2 = cp.Problem(objective2, constraints2)\n",
    "    problem2.solve()\n",
    "    b2_opt = b2.value\n",
    "    c2_opt = c2.value\n",
    "\n",
    "    return b1_opt, c1_opt, b2_opt, c2_opt, U\n",
    "\n",
    "def predict(X, b1_opt, c1_opt, b2_opt, c2_opt):\n",
    "    \"\"\"\n",
    "    Predicts the labels for the given data points using TSVM with learned hyperplanes.\n",
    "\n",
    "    Args:\n",
    "    - X: Input data points, shape (n_samples, n_features).\n",
    "    - b1_opt: Optimal weight vector for class 1 hyperplane.\n",
    "    - c1_opt: Optimal bias for class 1 hyperplane.\n",
    "    - b2_opt: Optimal weight vector for class -1 hyperplane.\n",
    "    - c2_opt: Optimal bias for class -1 hyperplane.\n",
    "\n",
    "    Returns:\n",
    "    - y_pred: Predicted labels for the data points, +1 or -1.\n",
    "    \"\"\"\n",
    "    # Calculate distance from hyperplane 1 (class +1)\n",
    "    distance_to_class1 = np.abs(np.dot(X, b1_opt) + c1_opt)\n",
    "    \n",
    "    # Calculate distance from hyperplane 2 (class -1)\n",
    "    distance_to_class2 = np.abs(np.dot(X, b2_opt) + c2_opt)\n",
    "    \n",
    "    # Assign label based on which hyperplane is closer\n",
    "    y_pred = np.where(distance_to_class1 < distance_to_class2, 1, -1)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.17%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.98      0.94      1033\n",
      "           1       0.72      0.37      0.48       167\n",
      "\n",
      "    accuracy                           0.89      1200\n",
      "   macro avg       0.81      0.67      0.71      1200\n",
      "weighted avg       0.88      0.89      0.88      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UTSVM\n",
    "n_universum=1100\n",
    "\n",
    "b1_opt, c1_opt, b2_opt, c2_opt, U  = UTSVM(\n",
    "    A, B, n_universum, C1=1.0, C2=1.0, Cu=1.0)\n",
    "\n",
    "# Predict on the train data\n",
    "y_pred = predict(X_train_dense, b1_opt, c1_opt, b2_opt, c2_opt)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class QSVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, mu=0.2):\n",
    "        self.mu = mu\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "        G, r = self.compute_G_and_r(X)\n",
    "        self.z, self.c = self.optimize_z_c(G, r, y, self.mu)\n",
    "        return self  # Return self instead of z and c\n",
    "\n",
    "    def predict(self, X):\n",
    "        r = self._compute_r_matrix(X)\n",
    "        return np.sign(r @ self.z + self.c)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "    def compute_G_and_r(self, X):\n",
    "        \"\"\"Compute the matrices G and r based on X.\"\"\"\n",
    "        m, n = X.shape\n",
    "        G = np.zeros((self.d, self.d))\n",
    "        r = np.zeros((m, self.d))\n",
    "        D_n = self.get_duplication_matrix(n)\n",
    "\n",
    "        print(\"Start computing G and r...\")\n",
    "        for i in tqdm(range(m)):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "            X_i = np.kron(np.eye(n), x_i.reshape(1, -1))\n",
    "            M_i = X_i @ D_n\n",
    "            H_i = np.hstack([M_i, np.eye(n)])\n",
    "            G += 2 * H_i.T @ H_i\n",
    "        print(\"Finished computing G and r...\\n\")\n",
    "\n",
    "        return G, r\n",
    "\n",
    "    def loss(self, z, G, r, y, c, mu):\n",
    "        square_loss = 0.5 * z.T @ G @ z\n",
    "        y_hat = r @ z + c\n",
    "        hinge_loss = np.sum(np.maximum(0, 1 - np.multiply(y, y_hat)))\n",
    "        return square_loss + mu * hinge_loss\n",
    "\n",
    "    def optimize_z_c(self, G, r, y, mu):\n",
    "        d = G.shape[0]\n",
    "        z = cp.Variable((d, 1))\n",
    "        c = cp.Variable()\n",
    "        y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "        square_loss = 0.5 * cp.quad_form(z, G)\n",
    "        y_hat = r @ z + c\n",
    "        hinge_loss = cp.sum(cp.maximum(0, 1 - cp.multiply(y, y_hat)))\n",
    "        objective = cp.Minimize(square_loss + mu * hinge_loss)\n",
    "        prob = cp.Problem(objective)\n",
    "        result = prob.solve(solver=cp.CLARABEL, verbose=False)\n",
    "\n",
    "        return z.value, c.value\n",
    "\n",
    "    def _compute_r_matrix(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def _compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n*n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n*n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n*n, (n*(n+1))//2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1200, 164)\n",
      "Test data shape: (300, 164)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalize data (important for SVM)\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train_dense)\n",
    "X_test_standard = scaler_standard.transform(X_test_dense)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_train_standard)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "k = (cumulative_variance>=0.9).argmax()+1\n",
    "\n",
    "pca= PCA(n_components=k)\n",
    "X_train_reduced = pca.fit_transform(X_train_standard)\n",
    "X_test_reduced = pca.transform(X_test_standard)\n",
    "\n",
    "print(f\"Training data shape: {X_train_reduced.shape}\")\n",
    "print(f\"Test data shape: {X_test_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start computing G and r...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [07:47<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing G and r...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "qsvm = QSVM(mu = 2)\n",
    "clf = qsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      1.00      0.96      1033\n",
      "           1       0.95      0.45      0.61       167\n",
      "\n",
      "    accuracy                           0.92      1200\n",
      "   macro avg       0.93      0.72      0.78      1200\n",
      "weighted avg       0.92      0.92      0.91      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = qsvm.predict(X_train_reduced)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UQSVM:\n",
    "    def __init__(self, C=1, C_u=1, epsilon=0.1, n_universum=10):\n",
    "\n",
    "        \"\"\"\n",
    "        Universum Quadratic SVM for any binary classification task.\n",
    "        Args:\n",
    "\n",
    "        - C: Regularization parameter for training data.\n",
    "        - C_u: Regularization parameter for universum data.\n",
    "        - epsilon: Margin for universum points.\n",
    "        - n_universum: Number of universum points to generate.\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.C_u = C_u\n",
    "        self.epsilon = epsilon\n",
    "        self.n_universum = n_universum\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the U-QSVM model.\n",
    "\n",
    "        X: Training data matrix.\n",
    "        y: Labels corresponding to rows of X.\n",
    "        \"\"\"\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "\n",
    "        # Separate positive and negative samples\n",
    "        A = X[y == 1]\n",
    "        B = X[y == -1]\n",
    "\n",
    "        # Generate Universum points by averaging randomly selected points from both classes\n",
    "        n_class1, n_features = A.shape\n",
    "        n_class_minus_1 = B.shape[0]\n",
    "        random_indices_class_1 = np.random.choice(n_class1, self.n_universum, replace=True)\n",
    "        random_indices_class_minus_1 = np.random.choice(n_class_minus_1, self.n_universum, replace=True)\n",
    "        U = (A[random_indices_class_1] + B[random_indices_class_minus_1]) / 2\n",
    "\n",
    "        # Compute G, r, and r_u matrices\n",
    "        G, r, r_u = self.compute_G_and_r_and_r_u(X, U)\n",
    "        self.z, self.c = self.optimize_z_c(G, r, y, r_u)\n",
    "\n",
    "        return self.z, self.c, U\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted U-QSVM model.\n",
    "\n",
    "        X: Test data (features).\n",
    "        \"\"\"\n",
    "        r = self._compute_r_matrix(X)\n",
    "        return np.sign(r @ self.z + self.c)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the U-QSVM model.\n",
    "\n",
    "        X: Test data (features).\n",
    "        y: True labels for the test data.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "    def compute_G_and_r_and_r_u(self, X, U):\n",
    "        \"\"\"Compute the matrices G, r, and r_u based on trainsing matrix X and Universum matrix U.\"\"\"\n",
    "        m, n = X.shape\n",
    "        G = np.zeros((self.d, self.d))\n",
    "        r = np.zeros((m, self.d))\n",
    "        D_n = self.get_duplication_matrix(n)\n",
    "\n",
    "        R, _ = U.shape\n",
    "        r_u = np.zeros((R, self.d))\n",
    "\n",
    "        print(\"Start computing G and r...\")\n",
    "        for i in tqdm(range(m)):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "            X_i = np.kron(np.eye(n), x_i.reshape(1, -1))\n",
    "            M_i = X_i @ D_n\n",
    "            H_i = np.hstack([M_i, np.eye(n)])\n",
    "            G += 2 * H_i.T @ H_i\n",
    "        print(\"Finished computing G and r...\")\n",
    "\n",
    "        print(\"Start computing r_u...\")\n",
    "        for i in tqdm(range(R)):\n",
    "            u_i = U[i, :]\n",
    "            s_u_i = self._compute_s_i(u_i)\n",
    "            r_u[i] = np.concatenate([s_u_i, u_i])\n",
    "        print(\"Finished computing r_u...\")\n",
    "\n",
    "        return G, r, r_u\n",
    "\n",
    "    def loss(self, z, G, r, y, c, r_u):\n",
    "        \"\"\"Compute the objective function for the U-QSVM model.\"\"\"\n",
    "        square_loss = 0.5 * z.T @ G @ z\n",
    "        hinge_loss = np.sum(np.maximum(0, 1 - np.multiply(y, r @ z + c)))\n",
    "        hinge_loss_Universum_1 = np.sum(np.maximum(0,  - self.epsilon + (r_u @ z + c)))\n",
    "        hinge_loss_Universum_2 = np.sum(np.maximum(0,  - self.epsilon - (r_u @ z + c)))\n",
    "        return square_loss + self.C * hinge_loss + self.C_u * (hinge_loss_Universum_1 + hinge_loss_Universum_2)\n",
    "\n",
    "    def optimize_z_c(self, G, r, y, r_u):\n",
    "        \"\"\"Optimize the parameters z and c using convex programming.\"\"\"\n",
    "        d = G.shape[0]\n",
    "        z = cp.Variable((d, 1))\n",
    "        c = cp.Variable()\n",
    "        y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "        square_loss = 0.5 * cp.quad_form(z, G)\n",
    "        hinge_loss = cp.sum(cp.maximum(0, 1 - cp.multiply(y, r @ z + c)))\n",
    "        hinge_loss_Universum_1 = cp.sum(cp.maximum(0,  - self.epsilon - (r_u @ z + c)))\n",
    "        hinge_loss_Universum_2 = cp.sum(cp.maximum(0,  - self.epsilon + (r_u @ z + c)))\n",
    "        objective = cp.Minimize(square_loss + self.C * hinge_loss + self.C_u * (hinge_loss_Universum_1 + hinge_loss_Universum_2))\n",
    "        prob = cp.Problem(objective)\n",
    "        result = prob.solve(solver=cp.SCS, verbose=False)  # Change solver if needed\n",
    "\n",
    "        return z.value, c.value\n",
    "\n",
    "    def _compute_r_matrix(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def _compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n * n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n * n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n * n, (n * (n + 1)) // 2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start computing G and r...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [07:30<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing G and r...\n",
      "Start computing r_u...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1289/1289 [00:00<00:00, 9494.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing r_u...\n"
     ]
    }
   ],
   "source": [
    "uqsvm = UQSVM(C=1.0, C_u=0.5, epsilon=0.3, n_universum=1289)\n",
    "clf = uqsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.33%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.99      0.95      1033\n",
      "           1       0.91      0.42      0.57       167\n",
      "\n",
      "    accuracy                           0.91      1200\n",
      "   macro avg       0.91      0.71      0.76      1200\n",
      "weighted avg       0.91      0.91      0.90      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = uqsvm.predict(X_train_reduced)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTSVM:\n",
    "    def __init__(self, C_1=1, C_2=1):\n",
    "\n",
    "        \"\"\"\n",
    "        Imbalanced Universum Quadratic Twin SVM for any binary classification task.\n",
    "        For each class, this model finds a quadratic function that passes through that class\n",
    "        but makes sure the other class stay away one unit! Universum points are generated\n",
    "        depending on the class that we are handling.\n",
    "\n",
    "        Args:\n",
    "        - C_1: Regularization parameter for class 1 points.\n",
    "        - C_2: Regularization parameter for class -1 points.\n",
    "        \"\"\"\n",
    "\n",
    "        self.C_1 = C_1\n",
    "        self.C_2 = C_2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the ImUQTSVM model.\n",
    "\n",
    "        X: Training data matrix.\n",
    "        y: Labels corresponding to rows of X.\n",
    "        \"\"\"\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "\n",
    "        # Separate positive and negative samples\n",
    "        A = X[y == 1]\n",
    "        B = X[y == -1]\n",
    "\n",
    "        # Undersample class -1 to construct a reduced majority matrix\n",
    "        m_1 = A.shape[0]\n",
    "        B_reduced_indices = np.random.choice(B.shape[0], m_1, replace=False)\n",
    "        B_reduced = B[B_reduced_indices]\n",
    "\n",
    "        m_2 = B.shape[0]\n",
    "        r = m_2 - m_1\n",
    "        # Create A_bar: Randomly choose rows from A with replacement\n",
    "        A_bar_indices = np.random.choice(m_1, r, replace=True)\n",
    "        A_bar = A[A_bar_indices]\n",
    "\n",
    "        # Create B_bar: Randomly choose rows from B without replacement\n",
    "        B_bar_indices = np.random.choice(m_2, r, replace=False)\n",
    "        B_bar = B[B_bar_indices]\n",
    "\n",
    "        # Compute r matrices\n",
    "        r_1 = self.compute_r(A)\n",
    "        r_2 = self.compute_r(B)\n",
    "        r_2_reduced = self.compute_r(B_reduced)\n",
    "\n",
    "\n",
    "        self.z_1, self.c_1 = self.optimize_z_1_c_1(r_1, r_2_reduced)\n",
    "        self.z_2, self.c_2 = self.optimize_z_2_c_2(r_2, r_1)\n",
    "\n",
    "        return self.z_1, self.c_1, self.z_2, self.c_2\n",
    "\n",
    "    def predict(self, X, z_1, c_1, z_2, c_2):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted UQTSVM model.\n",
    "        X: Test data (features).\n",
    "        \"\"\"\n",
    "        y_hat = np.ones(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            r_i = self.compute_r(X[i,:].reshape(1,-1))\n",
    "            H_i = self.compute_H(X[i,:])\n",
    "\n",
    "            numerator_1 = np.abs(r_i @ z_1 + c_1)\n",
    "            denominator_1 = np.linalg.norm(H_i @ z_1 + c_1) ** 2\n",
    "            numerator_2 = np.abs(r_i @ z_2 + c_2)\n",
    "            denominator_2 = np.linalg.norm(H_i @ z_2 + c_2) ** 2\n",
    "\n",
    "            expression_1 = numerator_1 / denominator_1\n",
    "            expression_2 = numerator_2 / denominator_2\n",
    "\n",
    "            if expression_1 >= expression_2:\n",
    "                y_hat[i] = -1\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the U-QSVM model.\n",
    "\n",
    "        X: Test data (features).\n",
    "        y: True labels for the test data.\n",
    "        \"\"\"\n",
    "        #predictions = self.predict(X, z_1, c_1, z_2, c_2)\n",
    "        predictions = self.predict(X, self.z_1, self.c_1, self.z_2, self.c_2)\n",
    "\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "\n",
    "    def compute_H(self, x):\n",
    "      n = x.shape[0]\n",
    "      s_x = self.compute_s_i(x)\n",
    "      r_x = np.concatenate([s_x, x])\n",
    "      X_x = np.kron(np.eye(n), x.reshape(1, -1))\n",
    "      D_n = self.get_duplication_matrix(n)\n",
    "      M_x = X_x @ D_n\n",
    "      H_x = np.hstack([M_x, np.eye(n)])\n",
    "      return H_x\n",
    "\n",
    "\n",
    "    def optimize_z_1_c_1(self, r_1, r_2):\n",
    "\n",
    "        d = r_1.shape[1]\n",
    "        z_1 = cp.Variable((d, 1))\n",
    "        c_1 = cp.Variable()\n",
    "\n",
    "        # Square loss for regression points\n",
    "        square_loss_1 = cp.sum_squares(r_1 @ z_1 + c_1)\n",
    "\n",
    "        # Slack variables for errors in class 2 and Universum\n",
    "        slack_class_2 = cp.Variable((r_2.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_2 = cp.Variable(r_2.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 2 satisfy the margin or account for errors\n",
    "        constraints.append(r_2 @ z_1 + c_1 <= -1 + slack_class_2)\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 2 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + self.C_1 * cp.sum(slack_class_2)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_1.value, c_1.value\n",
    "\n",
    "\n",
    "    def optimize_z_2_c_2(self, r_2, r_1):\n",
    "\n",
    "        d = r_2.shape[1]\n",
    "        z_2 = cp.Variable((d, 1))\n",
    "        c_2 = cp.Variable()\n",
    "\n",
    "        # Square loss for class 1 points\n",
    "        square_loss_1 = cp.sum_squares(r_2 @ z_2 + c_2)\n",
    "\n",
    "        # Slack variables for errors in class 1 and Universum\n",
    "        slack_class_1 = cp.Variable((r_1.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_1 = cp.Variable(r_1.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 1 satisfy the margin or account for errors\n",
    "        constraints.append(r_1 @ z_2 + c_2 >= 1 - slack_class_1)\n",
    "\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 1 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + self.C_2 * cp.sum(slack_class_1)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_2.value, c_2.value\n",
    "\n",
    "    def compute_r(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self.compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n * n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n * n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n * n, (n * (n + 1)) // 2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "C_1 = 1\n",
    "C_2 = 1\n",
    "\n",
    "# Step 2: Initialize and train the UQTSVM model (Assuming the class UQTSVM is already defined)\n",
    "qtsvm = QTSVM(C_1 = C_1, C_2 = C_2)\n",
    "z_1, c_1, z_2, c_2 = qtsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.42%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.96      0.96      1033\n",
      "           1       0.77      0.76      0.76       167\n",
      "\n",
      "    accuracy                           0.93      1200\n",
      "   macro avg       0.86      0.86      0.86      1200\n",
      "weighted avg       0.93      0.93      0.93      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = qtsvm.predict(X_train_reduced, z_1, c_1, z_2, c_2)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class UQTSVM:\n",
    "    def __init__(self, C_1=1, C_2=1, C_u=1, epsilon=0.15):\n",
    "\n",
    "        \"\"\"\n",
    "        Imbalanced Universum Quadratic Twin SVM for any binary classification task.\n",
    "        For each class, this model finds a quadratic function that passes through that class\n",
    "        but makes sure the other class stay away one unit! Universum points are generated\n",
    "        depending on the class that we are handling.\n",
    "\n",
    "        Args:\n",
    "        - C_1: Regularization parameter for class 1 points.\n",
    "        - C_2: Regularization parameter for class -1 points.\n",
    "        - C_u: Regularization parameter for Universum data.\n",
    "        - epsilon: Margin for universum points.\n",
    "        \"\"\"\n",
    "\n",
    "        self.C_1 = C_1\n",
    "        self.C_2 = C_2\n",
    "        self.C_u = C_u\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def fit(self, X, y, n_universum=1289):\n",
    "        \"\"\"\n",
    "        Fit the ImUQTSVM model.\n",
    "\n",
    "        X: Training data matrix.\n",
    "        y: Labels corresponding to rows of X.\n",
    "        \"\"\"\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "\n",
    "        # Separate positive and negative samples\n",
    "        A = X[y == 1]\n",
    "        B = X[y == -1]\n",
    "\n",
    "        # Undersample class -1 to construct a reduced majority matrix\n",
    "        m_1 = A.shape[0]\n",
    "        B_reduced_indices = np.random.choice(B.shape[0], m_1, replace=False)\n",
    "        B_reduced = B[B_reduced_indices]\n",
    "\n",
    "        m_2 = B.shape[0]\n",
    "        r = m_2 - m_1\n",
    "        # Create A_bar: Randomly choose rows from A with replacement\n",
    "        A_bar_indices = np.random.choice(m_1, r, replace=True)\n",
    "        A_bar = A[A_bar_indices]\n",
    "\n",
    "        # Create B_bar: Randomly choose rows from B without replacement\n",
    "        B_bar_indices = np.random.choice(m_2, r, replace=False)\n",
    "        B_bar = B[B_bar_indices]\n",
    "\n",
    "        # Generate Universum points\n",
    "        U = (A_bar + B_bar) / 2  # Initial Universum points\n",
    "        g = math.ceil(m_1 // 2)  # Reduced Universum size for class 1\n",
    "        U_reduced = U[np.random.choice(U.shape[0], g, replace=True)]\n",
    "\n",
    "        # Compute r matrices\n",
    "        r_1 = self.compute_r(A)\n",
    "        r_2 = self.compute_r(B)\n",
    "        r_2_reduced = self.compute_r(B_reduced)\n",
    "        r_u_full = self.compute_r(U)\n",
    "        r_u_reduced = self.compute_r(U_reduced)\n",
    "\n",
    "\n",
    "        self.z_1, self.c_1 = self.optimize_z_1_c_1(r_1, r_u_reduced, r_2_reduced)\n",
    "        self.z_2, self.c_2 = self.optimize_z_2_c_2(r_2, r_u_full, r_1)\n",
    "\n",
    "        return self.z_1, self.c_1, self.z_2, self.c_2, U\n",
    "\n",
    "    def predict(self, X, z_1, c_1, z_2, c_2):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted UQTSVM model.\n",
    "        X: Test data (features).\n",
    "        \"\"\"\n",
    "        y_hat = np.ones(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            r_i = self.compute_r(X[i,:].reshape(1,-1))\n",
    "            H_i = self.compute_H(X[i,:])\n",
    "\n",
    "            numerator_1 = np.abs(r_i @ z_1 + c_1)\n",
    "            denominator_1 = np.linalg.norm(H_i @ z_1 + c_1) ** 2\n",
    "            numerator_2 = np.abs(r_i @ z_2 + c_2)\n",
    "            denominator_2 = np.linalg.norm(H_i @ z_2 + c_2) ** 2\n",
    "\n",
    "            expression_1 = numerator_1 / denominator_1\n",
    "            expression_2 = numerator_2 / denominator_2\n",
    "\n",
    "            if expression_1 >= expression_2:\n",
    "                y_hat[i] = -1\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the U-QSVM model.\n",
    "\n",
    "        X: Test data (features).\n",
    "        y: True labels for the test data.\n",
    "        \"\"\"\n",
    "        #predictions = self.predict(X, z_1, c_1, z_2, c_2)\n",
    "        predictions = self.predict(X, self.z_1, self.c_1, self.z_2, self.c_2)\n",
    "\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "\n",
    "    def compute_H(self, x):\n",
    "      n = x.shape[0]\n",
    "      s_x = self.compute_s_i(x)\n",
    "      r_x = np.concatenate([s_x, x])\n",
    "      X_x = np.kron(np.eye(n), x.reshape(1, -1))\n",
    "      D_n = self.get_duplication_matrix(n)\n",
    "      M_x = X_x @ D_n\n",
    "      H_x = np.hstack([M_x, np.eye(n)])\n",
    "      return H_x\n",
    "\n",
    "\n",
    "    def optimize_z_1_c_1(self, r_1, r_u, r_2):\n",
    "\n",
    "        d = r_1.shape[1]\n",
    "        z_1 = cp.Variable((d, 1))\n",
    "        c_1 = cp.Variable()\n",
    "\n",
    "        # Square loss for regression points\n",
    "        square_loss_1 = cp.sum_squares(r_1 @ z_1 + c_1)\n",
    "\n",
    "        # Slack variables for errors in class 2 and Universum\n",
    "        slack_class_2 = cp.Variable((r_2.shape[0], 1), nonneg=True)\n",
    "        slack_universum = cp.Variable((r_u.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_2 = cp.Variable(r_2.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 2 satisfy the margin or account for errors\n",
    "        constraints.append(r_2 @ z_1 + c_1 <= -1 + slack_class_2)\n",
    "\n",
    "        # Ensure all Universum points satisfy the margin with epsilon tolerance\n",
    "        constraints.append(r_u @ z_1 + c_1 >= -1 + self.epsilon - slack_universum)\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 2 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + C_1 * cp.sum(slack_class_2)\n",
    "            + C_u * cp.sum(slack_universum)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_1.value, c_1.value\n",
    "\n",
    "\n",
    "    def optimize_z_2_c_2(self, r_2, r_u, r_1):\n",
    "\n",
    "        d = r_2.shape[1]\n",
    "        z_2 = cp.Variable((d, 1))\n",
    "        c_2 = cp.Variable()\n",
    "\n",
    "        # Square loss for class 1 points\n",
    "        square_loss_1 = cp.sum_squares(r_2 @ z_2 + c_2)\n",
    "\n",
    "        # Slack variables for errors in class 1 and Universum\n",
    "        slack_class_1 = cp.Variable((r_1.shape[0], 1), nonneg=True)\n",
    "        slack_universum = cp.Variable((r_u.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_1 = cp.Variable(r_1.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 1 satisfy the margin or account for errors\n",
    "        constraints.append(r_1 @ z_2 + c_2 >= 1 - slack_class_1)\n",
    "\n",
    "        # Ensure all Universum points satisfy the margin with epsilon tolerance\n",
    "        constraints.append(r_u @ z_2 + c_2 >= 1 - self.epsilon - slack_universum)\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 1 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + C_2 * cp.sum(slack_class_1)\n",
    "            + C_u * cp.sum(slack_universum)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_2.value, c_2.value\n",
    "\n",
    "    def compute_r(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self.compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n * n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n * n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n * n, (n * (n + 1)) // 2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1 = 1\n",
    "C_2 = 1\n",
    "C_u = 0.5\n",
    "epsilon = 0.1\n",
    "n_universum = 1289\n",
    "\n",
    "uqtsvm = UQTSVM(C_1 = C_1, C_2 = C_2, C_u = C_u, epsilon = epsilon)\n",
    "z_1, c_1, z_2, c_2, U = uqtsvm.fit(X_train_reduced, y_train, n_universum=1289)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.58%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.97      0.96      1033\n",
      "           1       0.79      0.73      0.76       167\n",
      "\n",
      "    accuracy                           0.94      1200\n",
      "   macro avg       0.87      0.85      0.86      1200\n",
      "weighted avg       0.93      0.94      0.93      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = uqtsvm.predict(X_train_reduced, z_1, c_1, z_2, c_2)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
