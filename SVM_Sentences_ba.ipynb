{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import os,glob\n",
    "import cv2\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to /Users/chengchengchen/extracted_files\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "# Path to the zip file\n",
    "zip_path = r'/Users/chengchengchen/Desktop/桌面清理大师/VSC/Sentiment_Labelled_Sentences.zip'  # Update with the correct path to combined.zip\n",
    "\n",
    "# Extract the zip file\n",
    "#with ZipFile(zip_path, 'r') as zip_ref:\n",
    "#    zip_ref.extractall('/content')  # Extract to /content or any preferred directory\n",
    "\n",
    "# Extract the zip file to a writable directory\n",
    "extract_path = os.path.expanduser('~/extracted_files')  # Extract to ~/extracted_files\n",
    "os.makedirs(extract_path, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "with ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)  # Extract to the specified writable directory\n",
    "\n",
    "print(f\"Files extracted to {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'amazon_cells_labelled.txt', 'readme.txt', 'yelp_labelled.txt', 'imdb_labelled.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the extracted folder\n",
    "extracted_folder = os.path.expanduser('~/extracted_files/sentiment labelled sentences')\n",
    "\n",
    "# Check and list contents\n",
    "if os.path.exists(extracted_folder):\n",
    "    print(os.listdir(extracted_folder))\n",
    "else:\n",
    "    print(f\"The folder {extracted_folder} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  score source\n",
      "0  A very, very, very slow-moving, aimless movie ...      0   imdb\n",
      "1  Not sure who was more lost - the flat characte...      0   imdb\n",
      "2  Attempting artiness with black & white and cle...      0   imdb\n",
      "3       Very little music or anything to speak of.        0   imdb\n",
      "4  The best scene in the movie was when Gerardo i...      1   imdb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the folder\n",
    "folder_path = os.path.expanduser('~/extracted_files/sentiment labelled sentences')\n",
    "\n",
    "# Files to load\n",
    "files = ['imdb_labelled.txt', 'amazon_cells_labelled.txt', 'yelp_labelled.txt']\n",
    "\n",
    "# Load all files into a single DataFrame\n",
    "dataframes = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['sentence', 'score'])\n",
    "    df['source'] = file.split('_')[0]  # Add a source column based on file name\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "1    1386\n",
      "0    1362\n",
      "Name: count, dtype: int64\n",
      "source  score\n",
      "amazon  0        500\n",
      "        1        500\n",
      "imdb    1        386\n",
      "        0        362\n",
      "yelp    0        500\n",
      "        1        500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['score'].value_counts())\n",
    "print(data.groupby('source')['score'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Combine all files into one DataFrame\n",
    "for file in files:\n",
    "    file_path = os.path.expanduser(f'{folder_path}/{file}')\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['sentence', 'score'])\n",
    "    dataframes.append(df)\n",
    "\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Preprocess the text\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=200)  # Limit features to 5000\n",
    "X = tfidf.fit_transform(data['sentence'])\n",
    "y = data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Soft-margin SVM using CVXPY\n",
    "def soft_margin_svm(X, y, C):\n",
    "    \"\"\"\n",
    "    Solves the soft-margin SVM problem using CVXPY\n",
    "    Args:\n",
    "    - X: Data matrix of shape (m, n) where m is the number of points and n is the dimension (features).\n",
    "    - y: Labels vector of shape (m,) with entries in {-1, 1}.\n",
    "    - C: Regularization parameter.\n",
    "    Returns:\n",
    "    - b: Coefficient vector of shape (n,)\n",
    "    - c: Intercept (scalar)\n",
    "    - xi: Slack variables vector of shape (m,)\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Define the variables\n",
    "    b = cp.Variable(n)    # weight vector\n",
    "    c = cp.Variable()     # bias\n",
    "    xi = cp.Variable(m)   # slack variables\n",
    "\n",
    "    # Define the objective function: minimize (1/2) * ||b||^2 + C * sum(xi)\n",
    "    objective = cp.Minimize(0.5 * cp.sum_squares(b) + C * cp.sum(xi))\n",
    "\n",
    "    # Define the constraints: y_i * (b^T x_i + c) >= 1 - xi_i, xi_i >= 0\n",
    "    constraints = [y[i] * (X[i] @ b + c) >= 1 - xi[i] for i in range(m)]\n",
    "    constraints += [xi >= 0]\n",
    "\n",
    "    # Solve the problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    # Return the solution: b, c, and xi\n",
    "    return b.value, c.value, xi.value\n",
    "\n",
    "# Function to predict using the learned SVM model\n",
    "def predict(X, b, c):\n",
    "    return np.sign(X @ b + c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert labels in y_train to 1 and -1\n",
    "# 1 is postive, -1 is negative\n",
    "y_train = np.where(y_train == 0, -1, y_train)  # Replace 0 with -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 79.48%\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.88      0.81      2171\n",
      "           1       0.86      0.71      0.78      2225\n",
      "\n",
      "    accuracy                           0.79      4396\n",
      "   macro avg       0.80      0.80      0.79      4396\n",
      "weighted avg       0.80      0.79      0.79      4396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Run the SVM (Soft-margin SVM)\n",
    "C = 1.0  # Regularization parameter\n",
    "b_opt, c_opt, xi_opt = soft_margin_svm(X_train, y_train, C)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred_train = predict(X_train, b_opt, c_opt)\n",
    "\n",
    "y_pred_test = predict(X_test, b_opt, c_opt)\n",
    "\n",
    "# Compute accuracy and display classification report\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsvm(A, B, C1=1.0, C2=1.0):\n",
    "    \"\"\"\n",
    "    TSVM\n",
    "\n",
    "    Args:\n",
    "    - A: Matrix of points for class 1 (positive class).\n",
    "    - B: Matrix of points for class -1 (negative class).\n",
    "    - n_universum: Number of Universum points to generate.\n",
    "    - C1: Regularization parameter for class 1.\n",
    "    - C2: Regularization parameter for class -1.\n",
    "\n",
    "    Returns:\n",
    "    - b1_opt, c1_opt: Optimal weight vector and bias for class 1 hyperplane.\n",
    "    - b2_opt, c2_opt: Optimal weight vector and bias for class -1 hyperplane.\n",
    "    \"\"\"\n",
    "\n",
    "    n_class1, n_features = A.shape\n",
    "    n_class_minus_1 = B.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Optimization variables for Class 1\n",
    "    b1 = cp.Variable(n_features)\n",
    "    c1 = cp.Variable()\n",
    "    xi1 = cp.Variable(n_class_minus_1)  # Slack variables for class -1 constraints\n",
    "    \n",
    "    # Optimization variables for Class 2\n",
    "    b2 = cp.Variable(n_features)\n",
    "    c2 = cp.Variable()\n",
    "    xi2 = cp.Variable(n_class1)  # Slack variables for class 1 constraints\n",
    "  \n",
    "\n",
    "    # Objective function for Class 1\n",
    "    objective1 = cp.Minimize(0.5 * cp.norm(A @ b1 + c1, 2)**2 + C1 * cp.sum(xi1))\n",
    "\n",
    "    # Constraints for Class 1\n",
    "    constraints1 = [\n",
    "        -B @ b1 - c1 + xi1 >= np.ones(n_class_minus_1),\n",
    "        xi1 >= 0  # Class -1 points\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 1\n",
    "    problem1 = cp.Problem(objective1, constraints1)\n",
    "    problem1.solve()\n",
    "    b1_opt = b1.value\n",
    "    c1_opt = c1.value\n",
    "\n",
    "    # Objective function for Class 2\n",
    "    objective2 = cp.Minimize(0.5 * cp.norm(B @ b2 + c2, 2)**2 + C2 * cp.sum(xi2))\n",
    "\n",
    "    # Constraints for Class 2\n",
    "    constraints2 = [\n",
    "        A @ b2 + c2 + xi2 >= np.ones(n_class1),\n",
    "        xi2 >= 0   # Class 1 points\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 2\n",
    "    problem2 = cp.Problem(objective2, constraints2)\n",
    "    problem2.solve()\n",
    "    b2_opt = b2.value\n",
    "    c2_opt = c2.value\n",
    "\n",
    "    return b1_opt, c1_opt, b2_opt, c2_opt\n",
    "\n",
    "def predict(X, b1_opt, c1_opt, b2_opt, c2_opt):\n",
    "    \"\"\"\n",
    "    Predicts the labels for the given data points using TSVM with learned hyperplanes.\n",
    "\n",
    "    Args:\n",
    "    - X: Input data points, shape (n_samples, n_features).\n",
    "    - b1_opt: Optimal weight vector for class 1 hyperplane.\n",
    "    - c1_opt: Optimal bias for class 1 hyperplane.\n",
    "    - b2_opt: Optimal weight vector for class -1 hyperplane.\n",
    "    - c2_opt: Optimal bias for class -1 hyperplane.\n",
    "\n",
    "    Returns:\n",
    "    - y_pred: Predicted labels for the data points, +1 or -1.\n",
    "    \"\"\"\n",
    "    # Calculate distance from hyperplane 1 (class +1)\n",
    "    distance_to_class1 = np.abs(np.dot(X, b1_opt) + c1_opt)\n",
    "    \n",
    "    # Calculate distance from hyperplane 2 (class -1)\n",
    "    distance_to_class2 = np.abs(np.dot(X, b2_opt) + c2_opt)\n",
    "    \n",
    "    # Assign label based on which hyperplane is closer\n",
    "    y_pred = np.where(distance_to_class1 < distance_to_class2, 1, -1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(42)\n",
    "\n",
    "A = X_train[y_train == 1]  \n",
    "B = X_train[y_train == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.50%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.85      0.80      2171\n",
      "           1       0.84      0.74      0.78      2225\n",
      "\n",
      "    accuracy                           0.80      4396\n",
      "   macro avg       0.80      0.80      0.79      4396\n",
      "weighted avg       0.80      0.80      0.79      4396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengchengchen/Desktop/桌面清理大师/VSC/venv/lib/python3.9/site-packages/cvxpy/problems/problem.py:1481: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train tSVM\n",
    "b1_opt, c1_opt, b2_opt, c2_opt  = tsvm(\n",
    "    A, B, C1=1.0, C2=1.0)\n",
    "\n",
    "X_train_dense = X_train.toarray()  # Convert to dense format\n",
    "\n",
    "# Predict on the train data\n",
    "y_pred = predict(X_train_dense, b1_opt, c1_opt, b2_opt, c2_opt)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class QSVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, mu=0.2):\n",
    "        self.mu = mu\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "        G, r = self.compute_G_and_r(X)\n",
    "        self.z, self.c = self.optimize_z_c(G, r, y, self.mu)\n",
    "        return self  # Return self instead of z and c\n",
    "\n",
    "    def predict(self, X):\n",
    "        r = self._compute_r_matrix(X)\n",
    "        return np.sign(r @ self.z + self.c)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "    def compute_G_and_r(self, X):\n",
    "        \"\"\"Compute the matrices G and r based on X.\"\"\"\n",
    "        m, n = X.shape\n",
    "        G = np.zeros((self.d, self.d))\n",
    "        r = np.zeros((m, self.d))\n",
    "        D_n = self.get_duplication_matrix(n)\n",
    "\n",
    "        print(\"Start computing G and r...\")\n",
    "        for i in tqdm(range(m)):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "            X_i = np.kron(np.eye(n), x_i.reshape(1, -1))\n",
    "            M_i = X_i @ D_n\n",
    "            H_i = np.hstack([M_i, np.eye(n)])\n",
    "            G += 2 * H_i.T @ H_i\n",
    "        print(\"Finished computing G and r...\\n\")\n",
    "\n",
    "        return G, r\n",
    "\n",
    "    def loss(self, z, G, r, y, c, mu):\n",
    "        square_loss = 0.5 * z.T @ G @ z\n",
    "        y_hat = r @ z + c\n",
    "        hinge_loss = np.sum(np.maximum(0, 1 - np.multiply(y, y_hat)))\n",
    "        return square_loss + mu * hinge_loss\n",
    "\n",
    "    def optimize_z_c(self, G, r, y, mu):\n",
    "        d = G.shape[0]\n",
    "        z = cp.Variable((d, 1))\n",
    "        c = cp.Variable()\n",
    "        y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "        square_loss = 0.5 * cp.quad_form(z, G)\n",
    "        y_hat = r @ z + c\n",
    "        hinge_loss = cp.sum(cp.maximum(0, 1 - cp.multiply(y, y_hat)))\n",
    "        objective = cp.Minimize(square_loss + mu * hinge_loss)\n",
    "        prob = cp.Problem(objective)\n",
    "        result = prob.solve(solver=cp.CLARABEL, verbose=False)\n",
    "\n",
    "        return z.value, c.value\n",
    "\n",
    "    def _compute_r_matrix(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def _compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n*n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n*n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n*n, (n*(n+1))//2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4396, 170)\n",
      "Test data shape: (1100, 170)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalize data (important for SVM)\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train_dense)\n",
    "X_test_standard = scaler_standard.transform(X_test_dense)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_train_standard)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "k = (cumulative_variance>=0.9).argmax()+1\n",
    "\n",
    "pca= PCA(n_components=k)\n",
    "X_train_reduced = pca.fit_transform(X_train_standard)\n",
    "X_test_reduced = pca.transform(X_test_standard)\n",
    "\n",
    "print(f\"Training data shape: {X_train_reduced.shape}\")\n",
    "print(f\"Test data shape: {X_test_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start computing G and r...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4396/4396 [40:53<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing G and r...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengchengchen/Desktop/桌面清理大师/VSC/venv/lib/python3.9/site-packages/cvxpy/problems/problem.py:1481: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "qsvm = QSVM(mu = 2)\n",
    "clf = qsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.01%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.87      0.84      2171\n",
      "           1       0.86      0.81      0.84      2225\n",
      "\n",
      "    accuracy                           0.84      4396\n",
      "   macro avg       0.84      0.84      0.84      4396\n",
      "weighted avg       0.84      0.84      0.84      4396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = qsvm.predict(X_train_reduced)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTSVM:\n",
    "    def __init__(self, C_1=1, C_2=1):\n",
    "\n",
    "        \"\"\"\n",
    "        Imbalanced Universum Quadratic Twin SVM for any binary classification task.\n",
    "        For each class, this model finds a quadratic function that passes through that class\n",
    "        but makes sure the other class stay away one unit! Universum points are generated\n",
    "        depending on the class that we are handling.\n",
    "\n",
    "        Args:\n",
    "        - C_1: Regularization parameter for class 1 points.\n",
    "        - C_2: Regularization parameter for class -1 points.\n",
    "        \"\"\"\n",
    "\n",
    "        self.C_1 = C_1\n",
    "        self.C_2 = C_2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the ImUQTSVM model.\n",
    "\n",
    "        X: Training data matrix.\n",
    "        y: Labels corresponding to rows of X.\n",
    "        \"\"\"\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "\n",
    "        # Separate positive and negative samples\n",
    "        A = X[y == 1]\n",
    "        B = X[y == -1]\n",
    "\n",
    "        # Undersample class -1 to construct a reduced majority matrix\n",
    "        m_1 = A.shape[0]\n",
    "        B_reduced_indices = np.random.choice(B.shape[0], m_1, replace=True)\n",
    "        B_reduced = B[B_reduced_indices]\n",
    "\n",
    "        m_2 = B.shape[0]\n",
    "        r = m_1 - m_2\n",
    "        # Create A_bar: Randomly choose rows from A with replacement\n",
    "        A_bar_indices = np.random.choice(m_1, r, replace=True)\n",
    "        A_bar = A[A_bar_indices]\n",
    "\n",
    "        # Create B_bar: Randomly choose rows from B without replacement\n",
    "        B_bar_indices = np.random.choice(m_2, r, replace=False)\n",
    "        B_bar = B[B_bar_indices]\n",
    "\n",
    "        # Compute r matrices\n",
    "        r_1 = self.compute_r(A)\n",
    "        r_2 = self.compute_r(B)\n",
    "        r_2_reduced = self.compute_r(B_reduced)\n",
    "\n",
    "\n",
    "        self.z_1, self.c_1 = self.optimize_z_1_c_1(r_1, r_2_reduced)\n",
    "        self.z_2, self.c_2 = self.optimize_z_2_c_2(r_2, r_1)\n",
    "\n",
    "        return self.z_1, self.c_1, self.z_2, self.c_2\n",
    "\n",
    "    def predict(self, X, z_1, c_1, z_2, c_2):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted UQTSVM model.\n",
    "        X: Test data (features).\n",
    "        \"\"\"\n",
    "        y_hat = np.ones(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            r_i = self.compute_r(X[i,:].reshape(1,-1))\n",
    "            H_i = self.compute_H(X[i,:])\n",
    "\n",
    "            numerator_1 = np.abs(r_i @ z_1 + c_1)\n",
    "            denominator_1 = np.linalg.norm(H_i @ z_1 + c_1) ** 2\n",
    "            numerator_2 = np.abs(r_i @ z_2 + c_2)\n",
    "            denominator_2 = np.linalg.norm(H_i @ z_2 + c_2) ** 2\n",
    "\n",
    "            expression_1 = numerator_1 / denominator_1\n",
    "            expression_2 = numerator_2 / denominator_2\n",
    "\n",
    "            if expression_1 >= expression_2:\n",
    "                y_hat[i] = -1\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the U-QSVM model.\n",
    "\n",
    "        X: Test data (features).\n",
    "        y: True labels for the test data.\n",
    "        \"\"\"\n",
    "        #predictions = self.predict(X, z_1, c_1, z_2, c_2)\n",
    "        predictions = self.predict(X, self.z_1, self.c_1, self.z_2, self.c_2)\n",
    "\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "\n",
    "    def compute_H(self, x):\n",
    "      n = x.shape[0]\n",
    "      s_x = self.compute_s_i(x)\n",
    "      r_x = np.concatenate([s_x, x])\n",
    "      X_x = np.kron(np.eye(n), x.reshape(1, -1))\n",
    "      D_n = self.get_duplication_matrix(n)\n",
    "      M_x = X_x @ D_n\n",
    "      H_x = np.hstack([M_x, np.eye(n)])\n",
    "      return H_x\n",
    "\n",
    "\n",
    "    def optimize_z_1_c_1(self, r_1, r_2):\n",
    "\n",
    "        d = r_1.shape[1]\n",
    "        z_1 = cp.Variable((d, 1))\n",
    "        c_1 = cp.Variable()\n",
    "\n",
    "        # Square loss for regression points\n",
    "        square_loss_1 = cp.sum_squares(r_1 @ z_1 + c_1)\n",
    "\n",
    "        # Slack variables for errors in class 2 and Universum\n",
    "        slack_class_2 = cp.Variable((r_2.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_2 = cp.Variable(r_2.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 2 satisfy the margin or account for errors\n",
    "        constraints.append(r_2 @ z_1 + c_1 <= -1 + slack_class_2)\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 2 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + self.C_1 * cp.sum(slack_class_2)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_1.value, c_1.value\n",
    "\n",
    "\n",
    "    def optimize_z_2_c_2(self, r_2, r_1):\n",
    "\n",
    "        d = r_2.shape[1]\n",
    "        z_2 = cp.Variable((d, 1))\n",
    "        c_2 = cp.Variable()\n",
    "\n",
    "        # Square loss for class 1 points\n",
    "        square_loss_1 = cp.sum_squares(r_2 @ z_2 + c_2)\n",
    "\n",
    "        # Slack variables for errors in class 1 and Universum\n",
    "        slack_class_1 = cp.Variable((r_1.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_1 = cp.Variable(r_1.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 1 satisfy the margin or account for errors\n",
    "        constraints.append(r_1 @ z_2 + c_2 >= 1 - slack_class_1)\n",
    "\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 1 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + self.C_2 * cp.sum(slack_class_1)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_2.value, c_2.value\n",
    "\n",
    "    def compute_r(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self.compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n * n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n * n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n * n, (n * (n + 1)) // 2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "C_1 = 1\n",
    "C_2 = 1\n",
    "\n",
    "# Step 2: Initialize and train the UQTSVM model (Assuming the class UQTSVM is already defined)\n",
    "qtsvm = QTSVM(C_1 = C_1, C_2 = C_2)\n",
    "z_1, c_1, z_2, c_2 = qtsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.63%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.92      0.90      2171\n",
      "           1       0.92      0.87      0.89      2225\n",
      "\n",
      "    accuracy                           0.90      4396\n",
      "   macro avg       0.90      0.90      0.90      4396\n",
      "weighted avg       0.90      0.90      0.90      4396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = qtsvm.predict(X_train_reduced, z_1, c_1, z_2, c_2)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
