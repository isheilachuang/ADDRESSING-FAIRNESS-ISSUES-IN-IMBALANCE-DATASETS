{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 09:46:57.832615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/vl/ffnrmcms5mx5g1pss893jh0r0000gn/T/ipykernel_29175/4253086930.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import os,glob\n",
    "import cv2\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1687, 1025)\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  1015  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1     0     0     0     0     0     0     1     0     0     0  ...     0   \n",
      "2     0     0     1     0     0     0     0     0     0     0  ...     0   \n",
      "3     0     0     1     0     0     0     0     0     0     0  ...     0   \n",
      "4     0     0     1     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   1016  1017  1018  1019  1020  1021  1022  1023      1024  \n",
      "0     0     0     0     0     0     0     0     0  positive  \n",
      "1     0     1     0     0     0     1     0     0  positive  \n",
      "2     0     0     0     0     0     0     0     0  positive  \n",
      "3     0     0     0     0     0     0     0     0  positive  \n",
      "4     0     0     0     0     0     0     0     1  positive  \n",
      "\n",
      "[5 rows x 1025 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/chencheng/Desktop/qsar_androgen_receptor.csv'  # Replace with the correct path\n",
    "df = pd.read_csv(file_path, sep=';', header=None)\n",
    "\n",
    "# Check the shape and first few rows\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded target:\n",
      "1024\n",
      "-1    1488\n",
      " 1     199\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "features = df.iloc[:, :-1]  # First 1024 columns (binary attributes)\n",
    "target = df.iloc[:, -1]     # Last column (class: positive/negative)\n",
    "\n",
    "# Encode the target to 1 and -1\n",
    "target = target.map({'positive': 1, 'negative': -1})\n",
    "\n",
    "# Verify the encoding\n",
    "print(\"Encoded target:\")\n",
    "print(target.value_counts())  # Check the distribution of 1 and -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced target distribution:\n",
      "1024\n",
      "-1    199\n",
      " 1    199\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Combine features and target into a single DataFrame\n",
    "df_balanced = pd.concat([features, target], axis=1)\n",
    "\n",
    "# Separate the majority and minority classes\n",
    "majority_class = df_balanced[df_balanced.iloc[:, -1] == -1]\n",
    "minority_class = df_balanced[df_balanced.iloc[:, -1] == 1]\n",
    "\n",
    "# Downsample the majority class\n",
    "majority_class_downsampled = resample(\n",
    "    majority_class,\n",
    "    replace=False,  # No replacement\n",
    "    n_samples=len(minority_class),  # Match minority class size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine the minority class with the downsampled majority class\n",
    "balanced_df = pd.concat([majority_class_downsampled, minority_class])\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target again\n",
    "features_balanced = balanced_df.iloc[:, :-1]\n",
    "target_balanced = balanced_df.iloc[:, -1]\n",
    "\n",
    "# Verify the new class distribution\n",
    "print(\"Balanced target distribution:\")\n",
    "print(target_balanced.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (318, 1024), (318,)\n",
      "Test set shape: (80, 1024), (80,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_balanced, target_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the splits\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Soft-margin SVM using CVXPY\n",
    "def soft_margin_svm(X, y, C):\n",
    "    \"\"\"\n",
    "    Solves the soft-margin SVM problem using CVXPY\n",
    "    Args:\n",
    "    - X: Data matrix of shape (m, n) where m is the number of points and n is the dimension (features).\n",
    "    - y: Labels vector of shape (m,) with entries in {-1, 1}.\n",
    "    - C: Regularization parameter.\n",
    "    Returns:\n",
    "    - b: Coefficient vector of shape (n,)\n",
    "    - c: Intercept (scalar)\n",
    "    - xi: Slack variables vector of shape (m,)\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Define the variables\n",
    "    b = cp.Variable(n)    # weight vector\n",
    "    c = cp.Variable()     # bias\n",
    "    xi = cp.Variable(m)   # slack variables\n",
    "\n",
    "    # Define the objective function: minimize (1/2) * ||b||^2 + C * sum(xi)\n",
    "    objective = cp.Minimize(0.5 * cp.sum_squares(b) + C * cp.sum(xi))\n",
    "\n",
    "    # Define the constraints: y_i * (b^T x_i + c) >= 1 - xi_i, xi_i >= 0\n",
    "    constraints = [y[i] * (X[i] @ b + c) >= 1 - xi[i] for i in range(m)]\n",
    "    constraints += [xi >= 0]\n",
    "\n",
    "    # Solve the problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    # Return the solution: b, c, and xi\n",
    "    return b.value, c.value, xi.value\n",
    "\n",
    "# Function to predict using the learned SVM model\n",
    "def predict(X, b, c):\n",
    "    return np.sign(X @ b + c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert to NumPy arrays if required\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       161\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Run the SVM (Soft-margin SVM)\n",
    "C = 1.0  # Regularization parameter\n",
    "b_opt, c_opt, xi_opt = soft_margin_svm(X_train, y_train, C)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred_train = predict(X_train, b_opt, c_opt)\n",
    "\n",
    "y_pred_test = predict(X_test, b_opt, c_opt)\n",
    "\n",
    "# Compute accuracy and display classification report\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsvm(A, B, C1=1.0, C2=1.0):\n",
    "    \"\"\"\n",
    "    TSVM\n",
    "\n",
    "    Args:\n",
    "    - A: Matrix of points for class 1 (positive class).\n",
    "    - B: Matrix of points for class -1 (negative class).\n",
    "    - n_universum: Number of Universum points to generate.\n",
    "    - C1: Regularization parameter for class 1.\n",
    "    - C2: Regularization parameter for class -1.\n",
    "\n",
    "    Returns:\n",
    "    - b1_opt, c1_opt: Optimal weight vector and bias for class 1 hyperplane.\n",
    "    - b2_opt, c2_opt: Optimal weight vector and bias for class -1 hyperplane.\n",
    "    \"\"\"\n",
    "\n",
    "    n_class1, n_features = A.shape\n",
    "    n_class_minus_1 = B.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Optimization variables for Class 1\n",
    "    b1 = cp.Variable(n_features)\n",
    "    c1 = cp.Variable()\n",
    "    xi1 = cp.Variable(n_class_minus_1)  # Slack variables for class -1 constraints\n",
    "    \n",
    "    # Optimization variables for Class 2\n",
    "    b2 = cp.Variable(n_features)\n",
    "    c2 = cp.Variable()\n",
    "    xi2 = cp.Variable(n_class1)  # Slack variables for class 1 constraints\n",
    "  \n",
    "\n",
    "    # Objective function for Class 1\n",
    "    objective1 = cp.Minimize(0.5 * cp.norm(A @ b1 + c1, 2)**2 + C1 * cp.sum(xi1))\n",
    "\n",
    "    # Constraints for Class 1\n",
    "    constraints1 = [\n",
    "        -B @ b1 - c1 + xi1 >= np.ones(n_class_minus_1),\n",
    "        xi1 >= 0  # Class -1 points\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 1\n",
    "    problem1 = cp.Problem(objective1, constraints1)\n",
    "    problem1.solve()\n",
    "    b1_opt = b1.value\n",
    "    c1_opt = c1.value\n",
    "\n",
    "    # Objective function for Class 2\n",
    "    objective2 = cp.Minimize(0.5 * cp.norm(B @ b2 + c2, 2)**2 + C2 * cp.sum(xi2))\n",
    "\n",
    "    # Constraints for Class 2\n",
    "    constraints2 = [\n",
    "        A @ b2 + c2 + xi2 >= np.ones(n_class1),\n",
    "        xi2 >= 0   # Class 1 points\n",
    "    ]\n",
    "\n",
    "    # Solve for Class 2\n",
    "    problem2 = cp.Problem(objective2, constraints2)\n",
    "    problem2.solve()\n",
    "    b2_opt = b2.value\n",
    "    c2_opt = c2.value\n",
    "\n",
    "    return b1_opt, c1_opt, b2_opt, c2_opt\n",
    "\n",
    "def predict(X, b1_opt, c1_opt, b2_opt, c2_opt):\n",
    "    \"\"\"\n",
    "    Predicts the labels for the given data points using TSVM with learned hyperplanes.\n",
    "\n",
    "    Args:\n",
    "    - X: Input data points, shape (n_samples, n_features).\n",
    "    - b1_opt: Optimal weight vector for class 1 hyperplane.\n",
    "    - c1_opt: Optimal bias for class 1 hyperplane.\n",
    "    - b2_opt: Optimal weight vector for class -1 hyperplane.\n",
    "    - c2_opt: Optimal bias for class -1 hyperplane.\n",
    "\n",
    "    Returns:\n",
    "    - y_pred: Predicted labels for the data points, +1 or -1.\n",
    "    \"\"\"\n",
    "    # Calculate distance from hyperplane 1 (class +1)\n",
    "    distance_to_class1 = np.abs(np.dot(X, b1_opt) + c1_opt)\n",
    "    \n",
    "    # Calculate distance from hyperplane 2 (class -1)\n",
    "    distance_to_class2 = np.abs(np.dot(X, b2_opt) + c2_opt)\n",
    "    \n",
    "    # Assign label based on which hyperplane is closer\n",
    "    y_pred = np.where(distance_to_class1 < distance_to_class2, 1, -1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(42)\n",
    "\n",
    "A = X_train[y_train == 1]  \n",
    "B = X_train[y_train == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       161\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train tSVM\n",
    "b1_opt, c1_opt, b2_opt, c2_opt  = tsvm(\n",
    "    A, B, C1=1.0, C2=1.0)\n",
    "\n",
    "\n",
    "# Predict on the train data\n",
    "y_pred = predict(X_train, b1_opt, c1_opt, b2_opt, c2_opt)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class QSVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, mu=0.2):\n",
    "        self.mu = mu\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "        G, r = self.compute_G_and_r(X)\n",
    "        self.z, self.c = self.optimize_z_c(G, r, y, self.mu)\n",
    "        return self  # Return self instead of z and c\n",
    "\n",
    "    def predict(self, X):\n",
    "        r = self._compute_r_matrix(X)\n",
    "        return np.sign(r @ self.z + self.c)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "    def compute_G_and_r(self, X):\n",
    "        \"\"\"Compute the matrices G and r based on X.\"\"\"\n",
    "        m, n = X.shape\n",
    "        G = np.zeros((self.d, self.d))\n",
    "        r = np.zeros((m, self.d))\n",
    "        D_n = self.get_duplication_matrix(n)\n",
    "\n",
    "        print(\"Start computing G and r...\")\n",
    "        for i in tqdm(range(m)):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "            X_i = np.kron(np.eye(n), x_i.reshape(1, -1))\n",
    "            M_i = X_i @ D_n\n",
    "            H_i = np.hstack([M_i, np.eye(n)])\n",
    "            G += 2 * H_i.T @ H_i\n",
    "        print(\"Finished computing G and r...\\n\")\n",
    "\n",
    "        return G, r\n",
    "\n",
    "    def loss(self, z, G, r, y, c, mu):\n",
    "        square_loss = 0.5 * z.T @ G @ z\n",
    "        y_hat = r @ z + c\n",
    "        hinge_loss = np.sum(np.maximum(0, 1 - np.multiply(y, y_hat)))\n",
    "        return square_loss + mu * hinge_loss\n",
    "\n",
    "    def optimize_z_c(self, G, r, y, mu):\n",
    "        d = G.shape[0]\n",
    "        z = cp.Variable((d, 1))\n",
    "        c = cp.Variable()\n",
    "        y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "        square_loss = 0.5 * cp.quad_form(z, G)\n",
    "        y_hat = r @ z + c\n",
    "        hinge_loss = cp.sum(cp.maximum(0, 1 - cp.multiply(y, y_hat)))\n",
    "        objective = cp.Minimize(square_loss + mu * hinge_loss)\n",
    "        prob = cp.Problem(objective)\n",
    "        result = prob.solve(solver=cp.CLARABEL, verbose=False)\n",
    "\n",
    "        return z.value, c.value\n",
    "\n",
    "    def _compute_r_matrix(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self._compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def _compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n*n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n*n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n*n, (n*(n+1))//2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (318, 171)\n",
      "Test data shape: (80, 171)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Normalize data (important for SVM)\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_train_standard)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()\n",
    "k = (cumulative_variance>=0.9).argmax()+1\n",
    "\n",
    "pca= PCA(n_components=k)\n",
    "X_train_reduced = pca.fit_transform(X_train_standard)\n",
    "X_test_reduced = pca.transform(X_test_standard)\n",
    "\n",
    "print(f\"Training data shape: {X_train_reduced.shape}\")\n",
    "print(f\"Test data shape: {X_test_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start computing G and r...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 318/318 [09:27<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing G and r...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "qsvm = QSVM(mu = 2)\n",
    "clf = qsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       161\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = qsvm.predict(X_train_reduced)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTSVM:\n",
    "    def __init__(self, C_1=1, C_2=1):\n",
    "\n",
    "        \"\"\"\n",
    "        Imbalanced Universum Quadratic Twin SVM for any binary classification task.\n",
    "        For each class, this model finds a quadratic function that passes through that class\n",
    "        but makes sure the other class stay away one unit! Universum points are generated\n",
    "        depending on the class that we are handling.\n",
    "\n",
    "        Args:\n",
    "        - C_1: Regularization parameter for class 1 points.\n",
    "        - C_2: Regularization parameter for class -1 points.\n",
    "        \"\"\"\n",
    "\n",
    "        self.C_1 = C_1\n",
    "        self.C_2 = C_2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the ImUQTSVM model.\n",
    "\n",
    "        X: Training data matrix.\n",
    "        y: Labels corresponding to rows of X.\n",
    "        \"\"\"\n",
    "        self.d = self._calculate_d(X.shape[1])  # Calculate dimensionality once\n",
    "\n",
    "        # Separate positive and negative samples\n",
    "        A = X[y == 1]\n",
    "        B = X[y == -1]\n",
    "\n",
    "        # Undersample class -1 to construct a reduced majority matrix\n",
    "        m_1 = A.shape[0]\n",
    "        B_reduced_indices = np.random.choice(B.shape[0], m_1, replace=False)\n",
    "        B_reduced = B[B_reduced_indices]\n",
    "\n",
    "        m_2 = B.shape[0]\n",
    "        r = m_2 - m_1\n",
    "        # Create A_bar: Randomly choose rows from A with replacement\n",
    "        A_bar_indices = np.random.choice(m_1, r, replace=True)\n",
    "        A_bar = A[A_bar_indices]\n",
    "\n",
    "        # Create B_bar: Randomly choose rows from B without replacement\n",
    "        B_bar_indices = np.random.choice(m_2, r, replace=False)\n",
    "        B_bar = B[B_bar_indices]\n",
    "\n",
    "        # Compute r matrices\n",
    "        r_1 = self.compute_r(A)\n",
    "        r_2 = self.compute_r(B)\n",
    "        r_2_reduced = self.compute_r(B_reduced)\n",
    "\n",
    "\n",
    "        self.z_1, self.c_1 = self.optimize_z_1_c_1(r_1, r_2_reduced)\n",
    "        self.z_2, self.c_2 = self.optimize_z_2_c_2(r_2, r_1)\n",
    "\n",
    "        return self.z_1, self.c_1, self.z_2, self.c_2\n",
    "\n",
    "    def predict(self, X, z_1, c_1, z_2, c_2):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted UQTSVM model.\n",
    "        X: Test data (features).\n",
    "        \"\"\"\n",
    "        y_hat = np.ones(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            r_i = self.compute_r(X[i,:].reshape(1,-1))\n",
    "            H_i = self.compute_H(X[i,:])\n",
    "\n",
    "            numerator_1 = np.abs(r_i @ z_1 + c_1)\n",
    "            denominator_1 = np.linalg.norm(H_i @ z_1 + c_1) ** 2\n",
    "            numerator_2 = np.abs(r_i @ z_2 + c_2)\n",
    "            denominator_2 = np.linalg.norm(H_i @ z_2 + c_2) ** 2\n",
    "\n",
    "            expression_1 = numerator_1 / denominator_1\n",
    "            expression_2 = numerator_2 / denominator_2\n",
    "\n",
    "            if expression_1 >= expression_2:\n",
    "                y_hat[i] = -1\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the U-QSVM model.\n",
    "\n",
    "        X: Test data (features).\n",
    "        y: True labels for the test data.\n",
    "        \"\"\"\n",
    "        #predictions = self.predict(X, z_1, c_1, z_2, c_2)\n",
    "        predictions = self.predict(X, self.z_1, self.c_1, self.z_2, self.c_2)\n",
    "\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "\n",
    "    def compute_H(self, x):\n",
    "      n = x.shape[0]\n",
    "      s_x = self.compute_s_i(x)\n",
    "      r_x = np.concatenate([s_x, x])\n",
    "      X_x = np.kron(np.eye(n), x.reshape(1, -1))\n",
    "      D_n = self.get_duplication_matrix(n)\n",
    "      M_x = X_x @ D_n\n",
    "      H_x = np.hstack([M_x, np.eye(n)])\n",
    "      return H_x\n",
    "\n",
    "\n",
    "    def optimize_z_1_c_1(self, r_1, r_2):\n",
    "\n",
    "        d = r_1.shape[1]\n",
    "        z_1 = cp.Variable((d, 1))\n",
    "        c_1 = cp.Variable()\n",
    "\n",
    "        # Square loss for regression points\n",
    "        square_loss_1 = cp.sum_squares(r_1 @ z_1 + c_1)\n",
    "\n",
    "        # Slack variables for errors in class 2 and Universum\n",
    "        slack_class_2 = cp.Variable((r_2.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_2 = cp.Variable(r_2.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 2 satisfy the margin or account for errors\n",
    "        constraints.append(r_2 @ z_1 + c_1 <= -1 + slack_class_2)\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 2 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + self.C_1 * cp.sum(slack_class_2)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_1.value, c_1.value\n",
    "\n",
    "\n",
    "    def optimize_z_2_c_2(self, r_2, r_1):\n",
    "\n",
    "        d = r_2.shape[1]\n",
    "        z_2 = cp.Variable((d, 1))\n",
    "        c_2 = cp.Variable()\n",
    "\n",
    "        # Square loss for class 1 points\n",
    "        square_loss_1 = cp.sum_squares(r_2 @ z_2 + c_2)\n",
    "\n",
    "        # Slack variables for errors in class 1 and Universum\n",
    "        slack_class_1 = cp.Variable((r_1.shape[0], 1), nonneg=True)\n",
    "\n",
    "        # slack_class_1 = cp.Variable(r_1.shape[0], nonneg=True)\n",
    "        # slack_universum = cp.Variable(r_u.shape[0], nonneg=True)\n",
    "\n",
    "        # Constraints\n",
    "        constraints = []\n",
    "\n",
    "        # Ensure all points in class 1 satisfy the margin or account for errors\n",
    "        constraints.append(r_1 @ z_2 + c_2 >= 1 - slack_class_1)\n",
    "\n",
    "\n",
    "        # Objective: Minimize square loss + hinge penalties for class 1 and Universum\n",
    "        objective = cp.Minimize(\n",
    "            square_loss_1\n",
    "            + self.C_2 * cp.sum(slack_class_1)\n",
    "        )\n",
    "\n",
    "        # Problem definition\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        prob.solve(solver=cp.SCS, verbose=False)  # Use any preferred solver\n",
    "\n",
    "        return z_2.value, c_2.value\n",
    "\n",
    "    def compute_r(self, X):\n",
    "        \"\"\"Helper to compute the r matrix for predictions.\"\"\"\n",
    "        m, n = X.shape\n",
    "        r = np.zeros((m, self.d))\n",
    "        for i in range(m):\n",
    "            x_i = X[i, :]\n",
    "            s_i = self.compute_s_i(x_i)\n",
    "            r[i] = np.concatenate([s_i, x_i])\n",
    "        return r\n",
    "\n",
    "    def compute_s_i(self, x_i):\n",
    "        \"\"\"Helper to compute s_i (half-vectorization) from x_i.\"\"\"\n",
    "        x_i_x_i_T = np.outer(x_i, x_i)\n",
    "        return 0.5 * self.hvec(x_i_x_i_T)\n",
    "\n",
    "    def hvec(self, A):\n",
    "        \"\"\"Half-vectorization of a symmetric matrix A.\"\"\"\n",
    "        indices = np.triu_indices(A.shape[0])\n",
    "        return A[indices]\n",
    "\n",
    "    def get_duplication_matrix(self, n):\n",
    "        \"\"\"Duplication matrix for vectorizing a symmetric matrix.\"\"\"\n",
    "        i_indices = np.arange(n * n)\n",
    "        j_indices = np.zeros((n, n), dtype=int)\n",
    "\n",
    "        z = 0\n",
    "        for x in range(n):\n",
    "            for y in range(x, n):\n",
    "                j_indices[x, y] = j_indices[y, x] = z\n",
    "                z += 1\n",
    "\n",
    "        j_indices_flat = j_indices.flatten()\n",
    "        data = np.ones(n * n, dtype=int)\n",
    "        return coo_matrix((data, (i_indices, j_indices_flat)), shape=(n * n, (n * (n + 1)) // 2))\n",
    "\n",
    "    def _calculate_d(self, n):\n",
    "        \"\"\"Helper to calculate the dimensionality once.\"\"\"\n",
    "        return n + n * (n + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "C_1 = 1\n",
    "C_2 = 1\n",
    "\n",
    "# Step 2: Initialize and train the UQTSVM model (Assuming the class UQTSVM is already defined)\n",
    "qtsvm = QTSVM(C_1 = C_1, C_2 = C_2)\n",
    "z_1, c_1, z_2, c_2 = qtsvm.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       161\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = qtsvm.predict(X_train_reduced, z_1, c_1, z_2, c_2)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
